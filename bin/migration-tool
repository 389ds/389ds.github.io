#! /usr/bin/env ruby

require 'bundler'
Bundler.setup(:default, :development)

require 'httparty'
require 'nokogiri'
require 'open3'
require 'stringex_lite'
require 'thor'
require 'uri'

class MediaWikiExport
  include HTTParty

  attr_reader :page_names
  def initialize(hostname, page_names)
    self.class.base_uri(hostname)
    @page_names = page_names
  end

  def post
    body = URI.encode_www_form({
      "catname" => "",
      "curonly" => "1",
      "pages" => page_names.join("\n"),
    })

    headers = {
      'Content-Type' => 'application/x-www-form-urlencoded',
      'Accept' => 'text/html,application/xml',
    }

    self.class.post("/index.php?title=Special:Export&action=submit",
                    :body => body,
                    :headers => headers).body
  end
end

class Page < Struct.new(:title, :content, :filename)
end

class MigrationTool < Thor
  include Thor::Actions

  desc "scrape HOSTNAME", "get a list of all wiki pages"
  option :quiet, :default => false, :type => :boolean, :hidden => true
  def scrape(host)
    url = "http://#{host}/index.php?title=Special%3AAllPages"
    pages = scrape_table(url)
    subpages = []
    pages.each do |p|
      if p.attributes['href'].to_s.include?("Special:AllPages")
        subpages << scrape_table("http://#{host}#{p.attributes['href']})")
      end
    end
    pages = subpages.flatten unless subpages.empty?
    pages = pages.map { |p| p.content }.uniq
    puts pages unless options[:quiet]
    pages
  end

  desc "files HOSTNAME", "download wiki files"
  option :directory, :default => File.join(Dir.pwd, "files"), :desc => "directory to write files to"
  def files(host)
    url = "http://#{host}/index.php?title=Special%3AAllPages&namespace=6"
    files = scrape_table(url)
    true_files = {}
    files.each do |f|
      name = f.content
      wikipage = URI.join("http://#{host}/", f.attributes['href'])
      doc = Nokogiri::HTML(open(wikipage))

      # Images and non-images (e.g. PDFs) have different locations in the DOM
      true_file = doc.at_css("div.fullMedia p a.internal") || doc.at_css("div#file a")
      unless true_file
        say("Could not find #{name}", :red)
        next
      end
      true_files[name] = URI.join("http://#{host}/", true_file.attributes['href'])
    end

    empty_directory(options[:directory]) unless File.exist?(options[:directory])
    true_files.each do |k, v|
      ext = File.extname(k).downcase
      name = File.basename(k, ext).to_url
      create_file(File.join(options[:directory], "#{name}#{ext}")) do
        HTTParty.get(v).parsed_response
      end
    end
  end

  desc "export HOSTNAME", "get a single XML file with all content"
  option :file, :default => "export.xml", :desc => "file to write export to"
  def export(host)
    pages = invoke(:scrape, [host], :quiet => true)
    xml = MediaWikiExport.new(host, pages).post
    create_file(options[:file], xml)
  end

  desc "migrate FILE", "migrate XML file to Markdown pages"
  option :directory, :default => Dir.pwd, :desc => "directory to write files to"
  def migrate(file)
    doc = Nokogiri::XML(File.open(file))

    # Generally not a great idea, but the export file only has one namespace
    doc.remove_namespaces!

    pages = []

    doc.xpath("/mediawiki/page").each do |p|
      title = (p.at_xpath('./title')) ? p.at_xpath('./title').content : ''
      content = (p.at_xpath('./revision/text')) ? p.at_xpath('./revision/text').content : ''

      # MediaWiki border directives confuse Pandoc
      content.gsub!(/\{\|\s+(border=\d+)/, "\1")
      pages << Page.new(title, content, "#{title.to_url}.md")
    end

    empty_directory(options[:directory]) unless File.exist?(options[:directory])
    pages.each do |p|
      front_matter = <<-FRONTMATTER.gsub(/^\s*/, '')
      ---
      title: "#{p.title}"
      ---
      FRONTMATTER
      command = "pandoc -f mediawiki -t markdown_github"
      stdout_s, stderr_s, status = Open3::capture3(command, :stdin_data => p.content)
      if status.success?
        file_content = front_matter + stdout_s
        create_file(File.join(options[:directory], p.filename), file_content)
      else
        error("Pandoc failed for #{p.title}: #{stderr_s}")
      end
    end

  end

  # Methods in the no_tasks block are not exposed to users
  no_tasks do
    def self.source_root
      File.expand_path("..", File.dirname(__FILE__))
    end

    # Builds a path within the source_root
    def path_to(*args)
      args = args.map(&:to_s)
      File.join(*args)
    end

    def scrape_table(url)
      doc = Nokogiri::HTML(open(url))
      pages = []
      doc.css("hr+table tr td a").each do |p|
        pages << p
      end
      pages
    end

    # If there is a file name conflict, rename the conflicting file.
    def create_file(destination, *args, &block)
      config = args.last.is_a?(Hash) ? args.pop : {}
      data = args.first
      suffix = ""
      while File.exist?(destination) do
        suffix += ".0"
        destination = destination + suffix
      end
      action CreateFile.new(self, destination, block || data.to_s, config)
    end
  end
end

MigrationTool.start(ARGV)
